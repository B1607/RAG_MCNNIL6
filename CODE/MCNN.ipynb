{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271c45cf-e40c-417c-a83e-03b375add143",
   "metadata": {},
   "source": [
    "# Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd76d2-6c8b-4901-896e-85c3a298082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,Model\n",
    "\n",
    "##\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import gc\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import loading_data as load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1e9da3-3fb9-4ed6-a197-380544b91cf7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PARAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851d5dd-21d4-4182-8fa5-2027de0091de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LABEL=load_data.data_label()\n",
    "\n",
    "\n",
    "\n",
    "MAXSEQ = 35\n",
    "NUM_FEATURE = 1024\n",
    "\n",
    "NUM_FILTER = 512\n",
    "NUM_HIDDEN = 1000#100\n",
    "BATCH_SIZE  = 128\n",
    "WINDOW_SIZES = [8,16,24,32]\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "CLASS_NAMES = ['Negative','Positive']\n",
    "\n",
    "EPOCHS      = 30\n",
    "K_Fold = 5\n",
    "VALIDATION_MODE=\"independent\"\n",
    "#\"independent\" \"cross\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1abe117-0b24-4a98-8f1e-57ad06c9e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"----------------------------------------------------------------------------------------------------\"\n",
    "# model fit batch funtion\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data, labels, batch_size):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.data))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_data = [self.data[i] for i in batch_indexes]\n",
    "        batch_labels = [self.labels[i] for i in batch_indexes]\n",
    "        return np.array(batch_data), np.array(batch_labels)\n",
    "    \n",
    "\"----------------------------------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad8130-4a7e-45ae-b873-d21cf32fd367",
   "metadata": {},
   "source": [
    "# MCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c0e76-2144-4ea4-a3d3-c66e0c563930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepScan(Model):\n",
    "\n",
    "\tdef __init__(self,\n",
    "\t             input_shape=(1, MAXSEQ, NUM_FEATURE),\n",
    "\t             window_sizes=[32],\n",
    "\t             num_filters=256,\n",
    "\t             num_hidden=1000):\n",
    "\t\tsuper(DeepScan, self).__init__()\n",
    "\t\t# Add input layer\n",
    "\t\tself.input_layer = tf.keras.Input(input_shape)\n",
    "\t\tself.window_sizes = window_sizes\n",
    "\t\tself.conv2d = []\n",
    "\t\tself.maxpool = []\n",
    "\t\tself.flatten = []\n",
    "\t\tfor window_size in self.window_sizes:\n",
    "\t\t\tself.conv2d.append(\n",
    "                layers.Conv2D(filters=num_filters,\n",
    "    \t\t\t              kernel_size=(1, window_size),\n",
    "\t\t\t                  activation=tf.nn.relu,\n",
    "\t\t\t                  padding='valid',\n",
    "\t\t\t                  bias_initializer=tf.constant_initializer(0.1),\n",
    "\t\t\t                  kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
    "                             )\n",
    "                             )\n",
    "\t\t\tself.maxpool.append(\n",
    "    \t\t\tlayers.MaxPooling2D(pool_size=(1, MAXSEQ - window_size + 1),\n",
    "\t\t\t                        strides=(1, MAXSEQ),\n",
    "\t\t\t                        padding='valid')\n",
    "                               )\n",
    "\t\t\tself.flatten.append(layers.Flatten())\n",
    "\t\tself.dropout = layers.Dropout(rate=0.7)\n",
    "\t\tself.fc1 = layers.Dense(num_hidden,\n",
    "                        \t\tactivation=tf.nn.relu,\n",
    "\t\t                        bias_initializer=tf.constant_initializer(0.1),\n",
    "\t\t                        kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
    "                               )\n",
    "\t\tself.fc2 = layers.Dense(NUM_CLASSES,\n",
    "\t\t                        activation='softmax',\n",
    "\t\t                        kernel_regularizer=tf.keras.regularizers.l2(1e-3)\n",
    "                               )\n",
    "\t\tself.out = self.call(self.input_layer)\n",
    "\n",
    "\tdef call(self, x, training=False):\n",
    "\t\t_x = []\n",
    "\t\tfor i in range(len(self.window_sizes)):\n",
    "\t\t\tx_conv = self.conv2d[i](x)\n",
    "\t\t\tx_maxp = self.maxpool[i](x_conv)\n",
    "\t\t\tx_flat = self.flatten[i](x_maxp)\n",
    "\t\t\t_x.append(x_flat)\n",
    "\n",
    "\t\tx = tf.concat(_x, 1)\n",
    "\t\tx = self.dropout(x, training=training)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.fc2(x) \n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd6e30-ad98-4e37-a76e-92cd7a39cfc6",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767da2b2-407b-45ab-8840-8056249aa086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "x_train,y_train,x_test,y_test= load_data.MCNN_data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f0a3d-be25-4106-a4b1-a4bee9f1aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(model, x_test, y_test):\n",
    "\n",
    "    print(x_test.shape)\n",
    "    pred_test = model.predict(x_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test[:,1], pred_test[:, 1])\n",
    "    AUC = metrics.auc(fpr, tpr)\n",
    "    gmeans = np.sqrt(tpr * (1-fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    print(f'Best Threshold={thresholds[ix]}, G-Mean={gmeans[ix]}')\n",
    "    threshold = thresholds[ix]\n",
    "\n",
    "    y_pred = (pred_test[:, 1] >= threshold).astype(int)\n",
    "\n",
    "    TN, FP, FN, TP =  metrics.confusion_matrix(y_test[0:][:,1], y_pred).ravel()\n",
    "\n",
    "    Sens = TP/(TP+FN) if TP+FN > 0 else 0.0\n",
    "    Spec = TN/(FP+TN) if FP+TN > 0 else 0.0\n",
    "    Acc = (TP+TN)/(TP+FP+TN+FN)\n",
    "    MCC = (TP*TN-FP*FN)/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)) if TP+FP > 0 and FP+TN > 0 and TP+FN and TN+FN else 0.0\n",
    "    F1 = 2*TP/(2*TP+FP+FN)\n",
    "    Prec=TP/(TP+FP)\n",
    "    Recall=TP/(TP+FN)\n",
    "    print(f'TP={TP}, FP={FP}, TN={TN}, FN={FN}, Sens={Sens:.4f}, Spec={Spec:.4f}, Acc={Acc:.4f}, MCC={MCC:.4f}, AUC={AUC:.4f}, F1={F1:.4f}, Prec={Prec:.4f}, Recall={Recall:.4f}\\n')\n",
    "    return TP,FP,TN,FN,Sens,Spec,Acc,MCC,AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314bd9a-10f4-40ef-a0b1-2d3788a6ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(VALIDATION_MODE==\"cross\"):\n",
    "\t\n",
    "\tkfold = KFold(n_splits = K_Fold, shuffle = True, random_state = 2)\n",
    "\tresults=[]\n",
    "\ti=1\n",
    "\tfor train_index, test_index in kfold.split(x_train):\n",
    "\t\tprint(i,\"/\",K_Fold,'\\n')\n",
    "\t\t# 取得訓練和測試數據\n",
    "\t\tX_train, X_test = x_train[train_index], x_train[test_index]\n",
    "\t\tY_train, Y_test = y_train[train_index], y_train[test_index]\n",
    "\t\tX_train,Y_train=IMBALANCE_funct(IMBALANCE,X_train,Y_train)\n",
    "\t\tgenerator = DataGenerator(X_train, Y_train, batch_size=BATCH_SIZE)\n",
    "\t\tmodel = DeepScan(\n",
    "\t\tnum_filters=NUM_FILTER,\n",
    "\t\t\tnum_hidden=NUM_HIDDEN,\n",
    "\t\t\twindow_sizes=WINDOW_SIZES)\n",
    "\t\tmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\t\tmodel.build(input_shape=X_train.shape)\n",
    "\t\thistory=model.fit(\n",
    "\t\t\tgenerator,\n",
    "\t\t\tepochs=EPOCHS,\n",
    "\t\t\tcallbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)],\n",
    "\t\t\tverbose=1,\n",
    "\t\t\tshuffle=True\n",
    "\t\t)\n",
    "\t\tTP, FP, TN, FN, Sens, Spec, Acc, MCC, AUC = model_test(model, X_test, Y_test)\n",
    "\t\tresults.append([TP, FP, TN, FN, Sens, Spec, Acc, MCC, AUC])\n",
    "\t\ti+=1\n",
    "\t\t\n",
    "\t\tdel X_train\n",
    "\t\tdel X_test\n",
    "\t\tdel Y_train\n",
    "\t\tdel Y_test\n",
    "\t\tgc.collect()\n",
    "\t\t\n",
    "\tmean_results = np.mean(results, axis=0)\n",
    "\tprint(f'TP={mean_results[0]:.4}, FP={mean_results[1]:.4}, TN={mean_results[2]:.4}, FN={mean_results[3]:.4}, Sens={mean_results[4]:.4}, Spec={mean_results[5]:.4}, Acc={mean_results[6]:.4}, MCC={mean_results[7]:.4}, AUC={mean_results[8]:.4}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa9cbe-3dc7-41a0-af37-8b2baffd372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(VALIDATION_MODE==\"independent\"):\n",
    "    x_train,y_train=IMBALANCE_funct(IMBALANCE,x_train,y_train)\n",
    "    generator = DataGenerator(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "    model = DeepScan(\n",
    "    \tnum_filters=NUM_FILTER,\n",
    "    \tnum_hidden=NUM_HIDDEN,\n",
    "    \twindow_sizes=WINDOW_SIZES)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.build(input_shape=x_train.shape)\n",
    "    model.summary()\n",
    "    model.fit(\n",
    "    \tgenerator,\n",
    "    \tepochs=EPOCHS,\n",
    "    \tshuffle=True,\n",
    "    )\n",
    "    TP,FP,TN,FN,Sens,Spec,Acc,MCC,AUC = model_test(model, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
